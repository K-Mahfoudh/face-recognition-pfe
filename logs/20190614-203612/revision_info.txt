arguments: C:/Users/s/Desktop/face_recognition_pfe/face_recognition_pfe/train_tripletloss.py
--------------------
git hash: b'c2b86a216de8d30de5f9dd782fba78a8bf48d261'
--------------------
b'diff --git a/.idea/face_recognition_pfe.iml b/.idea/face_recognition_pfe.iml\nindex 6ec3e13..4d62a73 100644\n--- a/.idea/face_recognition_pfe.iml\n+++ b/.idea/face_recognition_pfe.iml\n@@ -2,7 +2,7 @@\n <module type="PYTHON_MODULE" version="4">\n   <component name="NewModuleRootManager">\n     <content url="file://$MODULE_DIR$" />\n-    <orderEntry type="jdk" jdkName="Python 3.5 (faceNet)" jdkType="Python SDK" />\n+    <orderEntry type="jdk" jdkName="Python 3.5 (faceRecognition)" jdkType="Python SDK" />\n     <orderEntry type="sourceFolder" forTests="false" />\n   </component>\n   <component name="TestRunnerService">\ndiff --git a/.idea/misc.xml b/.idea/misc.xml\nindex 70c6285..12e85d4 100644\n--- a/.idea/misc.xml\n+++ b/.idea/misc.xml\n@@ -1,4 +1,4 @@\n <?xml version="1.0" encoding="UTF-8"?>\n <project version="4">\n-  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.5 (faceNet)" project-jdk-type="Python SDK" />\n+  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.5 (faceRecognition)" project-jdk-type="Python SDK" />\n </project>\n\\ No newline at end of file\ndiff --git a/.idea/vcs.xml b/.idea/vcs.xml\nnew file mode 100644\nindex 0000000..94a25f7\n--- /dev/null\n+++ b/.idea/vcs.xml\n@@ -0,0 +1,6 @@\n+<?xml version="1.0" encoding="UTF-8"?>\n+<project version="4">\n+  <component name="VcsDirectoryMappings">\n+    <mapping directory="$PROJECT_DIR$" vcs="Git" />\n+  </component>\n+</project>\n\\ No newline at end of file\ndiff --git a/.idea/workspace.xml b/.idea/workspace.xml\nindex 5b860e2..ecb6d73 100644\n--- a/.idea/workspace.xml\n+++ b/.idea/workspace.xml\n@@ -1,7 +1,60 @@\n <?xml version="1.0" encoding="UTF-8"?>\n <project version="4">\n   <component name="ChangeListManager">\n-    <list default="true" id="b4a709c4-3f79-4965-a8ce-da3ea2e5b613" name="Default Changelist" comment="" />\n+    <list default="true" id="b4a709c4-3f79-4965-a8ce-da3ea2e5b613" name="Default Changelist" comment="">\n+      <change afterPath="$PROJECT_DIR$/.idea/vcs.xml" afterDir="false" />\n+      <change beforePath="$PROJECT_DIR$/.idea/face_recognition_pfe.iml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/face_recognition_pfe.iml" afterDir="false" />\n+      <change beforePath="$PROJECT_DIR$/.idea/misc.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/misc.xml" afterDir="false" />\n+      <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />\n+      <change beforePath="$PROJECT_DIR$/align/align_dataset_mtcnn.py" beforeDir="false" afterPath="$PROJECT_DIR$/align/align_dataset_mtcnn.py" afterDir="false" />\n+      <change beforePath="$PROJECT_DIR$/compare.py" beforeDir="false" afterPath="$PROJECT_DIR$/compare.py" afterDir="false" />\n+      <change beforePath="$PROJECT_DIR$/face.py" beforeDir="false" afterPath="$PROJECT_DIR$/face.py" afterDir="false" />\n+      <change beforePath="$PROJECT_DIR$/myclassifier/my_classifier.pkl" beforeDir="false" afterPath="$PROJECT_DIR$/myclassifier/my_classifier.pkl" afterDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/Mahfoudh/WIN_20190527_16_24_02_Pro.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/Mahfoudh/WIN_20190530_16_46_19_Pro.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/Mahfoudh/WIN_20190530_16_46_21_Pro.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/Mahfoudh/WIN_20190530_16_46_22_Pro.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/Mahfoudh/WIN_20190530_16_46_25_Pro.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/Mahfoudh/WIN_20190530_16_46_30_Pro.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/Mahfoudh/WIN_20190531_15_42_20_Pro.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/Mahfoudh/WIN_20190531_15_42_22_Pro.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/Mahfoudh/WIN_20190531_15_42_24_Pro.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/Mahfoudh/WIN_20190531_15_42_25_Pro.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/Mahfoudh/WIN_20190531_15_42_27_Pro.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/Mahfoudh/WIN_20190531_15_42_29_Pro.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/Mahfoudh/imresizer.com (2).png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/Mahfoudh/profiles-pic.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/dakota/1223426.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/dakota/85.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/dakota/AP868390099291_1_EffieGray.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/dakota/Dakota-Fanning-5.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/dakota/Dakota-Fanning.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/dakota/Dakota_Fanning,_2009.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/dakota/Dakota_Fanning.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/dakota/Dakota_Fanning_Very_Good_Girls_Premiere_(cropped).png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/dakota/dakota-fanning (1).png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/dakota/dakota-fanning,-yeux-bleus-247878.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/dakota/dakota-fanning-28183-display.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/dakota/dakota-fanning-6.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/dakota/dakota-fanning-by-daniel-bergeron.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/dakota/dakota_fanning_getty_h_2016.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/obama/1024px-Barack_Obama_speaks_in_Cairo,_Egypt_06-04-09.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/obama/1028782502.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/obama/104656161-gettyimages-688156110.1910x1000.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/obama/170px-BarackObamaportrait.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/obama/190307-barack-obama-al-0826_3c9fdc71dc9476f764088b0e0290fd95.nbcnews-fp-760-360.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/obama/984661-barack-obama-lors-de-sa-derniere-conference-de-presse-a-la-maison-blanche-a-washington-le-18-janvier (1).png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/obama/984661-barack-obama-lors-de-sa-derniere-conference-de-presse-a-la-maison-blanche-a-washington-le-18-janvier.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/obama/Barack-Obama-en-campagne-derriere-les-democrates-pour-reconquerir-le-Congres.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/obama/Barack-Obama.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/obama/_93339875_obamalaughing.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/obama/barack\xc3\xa82.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/obama/images (4).png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/obama/images (5).png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/output/obama/obama_sotu_2016_ap_img.png" beforeDir="false" />\n+      <change beforePath="$PROJECT_DIR$/real_time_face_recognition_ip_webcam.py" beforeDir="false" afterPath="$PROJECT_DIR$/real_time_face_recognition_ip_webcam.py" afterDir="false" />\n+      <change beforePath="$PROJECT_DIR$/real_time_face_recognition_laptop_cam.py" beforeDir="false" afterPath="$PROJECT_DIR$/real_time_face_recognition_laptop_cam.py" afterDir="false" />\n+    </list>\n     <option name="EXCLUDED_CONVERTED_TO_IGNORED" value="true" />\n     <option name="SHOW_DIALOG" value="false" />\n     <option name="HIGHLIGHT_CONFLICTS" value="true" />\n@@ -9,109 +62,142 @@\n     <option name="LAST_RESOLUTION" value="IGNORE" />\n   </component>\n   <component name="FileEditorManager">\n-    <leaf>\n+    <leaf SIDE_TABS_SIZE_LIMIT_KEY="300">\n       <file pinned="false" current-in-tab="false">\n-        <entry file="file://$PROJECT_DIR$/align/align_dataset_mtcnn.py">\n+        <entry file="file://$PROJECT_DIR$/real_time_face_recognition_laptop_cam.py">\n           <provider selected="true" editor-type-id="text-editor">\n-            <state relative-caret-position="522">\n-              <caret line="81" column="22" selection-start-line="81" selection-start-column="22" selection-end-line="81" selection-end-column="22" />\n+            <state relative-caret-position="738">\n+              <caret line="41" column="21" selection-start-line="41" selection-start-column="21" selection-end-line="41" selection-end-column="21" />\n             </state>\n           </provider>\n         </entry>\n       </file>\n       <file pinned="false" current-in-tab="false">\n-        <entry file="file://$PROJECT_DIR$/real_time_face_recognition_laptop_cam.py">\n+        <entry file="file://$PROJECT_DIR$/cluster.py">\n           <provider selected="true" editor-type-id="text-editor">\n-            <state relative-caret-position="-396">\n-              <caret line="31" column="44" lean-forward="true" selection-start-line="31" selection-start-column="44" selection-end-line="31" selection-end-column="44" />\n+            <state relative-caret-position="440">\n+              <caret line="93" column="31" selection-start-line="93" selection-start-column="31" selection-end-line="93" selection-end-column="31" />\n               <folding>\n-                <element signature="e#1245#1260#0" expanded="true" />\n+                <element signature="e#1217#1255#0" expanded="true" />\n               </folding>\n             </state>\n           </provider>\n         </entry>\n       </file>\n-      <file pinned="false" current-in-tab="false">\n-        <entry file="file://$PROJECT_DIR$/real_time_face_recognition_ip_webcam.py">\n+      <file pinned="false" current-in-tab="true">\n+        <entry file="file://$PROJECT_DIR$/train_tripletloss.py">\n           <provider selected="true" editor-type-id="text-editor">\n-            <state relative-caret-position="-252">\n-              <caret line="38" column="51" lean-forward="true" selection-start-line="38" selection-start-column="51" selection-end-line="38" selection-end-column="51" />\n+            <state relative-caret-position="173">\n+              <caret line="445" column="42" lean-forward="true" selection-start-line="445" selection-start-column="42" selection-end-line="445" selection-end-column="42" />\n               <folding>\n-                <element signature="e#1245#1260#0" expanded="true" />\n+                <element signature="e#1289#1327#0" expanded="true" />\n               </folding>\n             </state>\n           </provider>\n         </entry>\n       </file>\n-      <file pinned="false" current-in-tab="true">\n-        <entry file="file://$PROJECT_DIR$/face.py">\n+      <file pinned="false" current-in-tab="false">\n+        <entry file="file://$PROJECT_DIR$/align/detect_face.py">\n           <provider selected="true" editor-type-id="text-editor">\n-            <state relative-caret-position="132">\n-              <caret line="123" column="22" lean-forward="true" selection-start-line="123" selection-start-column="22" selection-end-line="123" selection-end-column="22" />\n+            <state relative-caret-position="5724">\n+              <caret line="327" column="44" selection-start-line="327" selection-start-column="44" selection-end-line="327" selection-end-column="44" />\n             </state>\n           </provider>\n         </entry>\n       </file>\n       <file pinned="false" current-in-tab="false">\n-        <entry file="file://$PROJECT_DIR$/facenet.py">\n+        <entry file="file://$PROJECT_DIR$/align/align_dataset_mtcnn.py">\n           <provider selected="true" editor-type-id="text-editor">\n-            <state relative-caret-position="2562">\n-              <caret line="493" column="37" selection-start-line="493" selection-start-column="37" selection-end-line="493" selection-end-column="37" />\n+            <state relative-caret-position="486">\n+              <caret line="40" column="46" selection-start-line="40" selection-start-column="46" selection-end-line="40" selection-end-column="46" />\n+              <folding>\n+                <element signature="e#1196#1234#0" expanded="true" />\n+              </folding>\n             </state>\n           </provider>\n         </entry>\n       </file>\n       <file pinned="false" current-in-tab="false">\n-        <entry file="file://$PROJECT_DIR$/classifier.py">\n+        <entry file="file://$PROJECT_DIR$/facenet.py">\n           <provider selected="true" editor-type-id="text-editor">\n-            <state relative-caret-position="148">\n-              <caret line="40" column="33" lean-forward="true" selection-start-line="40" selection-start-column="33" selection-end-line="40" selection-end-column="33" />\n-              <folding>\n-                <element signature="e#1209#1247#0" expanded="true" />\n-              </folding>\n+            <state relative-caret-position="3924">\n+              <caret line="233" selection-start-line="233" selection-end-line="233" />\n             </state>\n           </provider>\n         </entry>\n       </file>\n     </leaf>\n   </component>\n+  <component name="FileTemplateManagerImpl">\n+    <option name="RECENT_TEMPLATES">\n+      <list>\n+        <option value="Python Script" />\n+      </list>\n+    </option>\n+  </component>\n   <component name="FindInProjectRecents">\n     <findStrings>\n-      <find>names</find>\n-      <find>name</find>\n-      <find>person</find>\n-      <find>face</find>\n-      <find>Faces</find>\n-      <find>find_faces</find>\n-      <find>args.</find>\n-      <find>pretrain</find>\n-      <find>detect</find>\n-      <find>args.data_di\'</find>\n-      <find>Identify</find>\n-      <find>url</find>\n+      <find>image_files</find>\n+      <find>\'./</find>\n+      <find>PermissionError: [Errno 13] Permission denied: \'.\'</find>\n       <find>tresh</find>\n-      <find>faces</find>\n+      <find>./outp</find>\n       <find>threshold</find>\n+      <find>identify</find>\n+      <find>print(face</find>\n+      <find>output</find>\n+      <find>misc</find>\n+      <find>scaled</find>\n+      <find>faces</find>\n+      <find>model</find>\n+      <find>data_</find>\n+      <find>place</find>\n+      <find>out_dir</find>\n+      <find>margin</find>\n+      <find>placeholder</find>\n+      <find>images</find>\n+      <find>recognition</find>\n+      <find>load</find>\n+      <find>print</find>\n+      <find>input</find>\n+      <find>args.output</find>\n+      <find>args.model</find>\n+      <find>print-</find>\n+      <find>tmp</find>\n+      <find>mak</find>\n+      <find>np.do</find>\n+      <find>args.pret</find>\n     </findStrings>\n   </component>\n+  <component name="Git.Settings">\n+    <option name="RECENT_GIT_ROOT_PATH" value="$PROJECT_DIR$" />\n+  </component>\n   <component name="IdeDocumentHistory">\n     <option name="CHANGED_PATHS">\n       <list>\n-        <option value="$PROJECT_DIR$/train_tripletloss.py" />\n         <option value="$PROJECT_DIR$/train_softmax.py" />\n+        <option value="$PROJECT_DIR$/compare.py" />\n+        <option value="$PROJECT_DIR$/real_time_face_recognition_ip_webcam.py" />\n         <option value="$PROJECT_DIR$/classifier.py" />\n-        <option value="$PROJECT_DIR$/real_time_face_recognition_laptop_cam.py" />\n+        <option value="$PROJECT_DIR$/testCluster.py" />\n         <option value="$PROJECT_DIR$/face.py" />\n-        <option value="$PROJECT_DIR$/real_time_face_recognition_ip_webcam.py" />\n+        <option value="$PROJECT_DIR$/align/detect_face.py" />\n+        <option value="$PROJECT_DIR$/send_package.py" />\n+        <option value="$PROJECT_DIR$/cluster.py" />\n+        <option value="$PROJECT_DIR$/align/align_dataset_mtcnn.py" />\n+        <option value="$PROJECT_DIR$/clustering.py" />\n+        <option value="$PROJECT_DIR$/real_time_face_recognition_laptop_cam.py" />\n+        <option value="$PROJECT_DIR$/train_tripletloss.py" />\n       </list>\n     </option>\n   </component>\n-  <component name="ProjectFrameBounds" extendedState="7">\n+  <component name="ProjectFrameBounds" extendedState="6">\n     <option name="x" value="85" />\n     <option name="y" value="25" />\n     <option name="width" value="1750" />\n     <option name="height" value="980" />\n   </component>\n+  <component name="ProjectLevelVcsManager" settingsEditedManually="true" />\n   <component name="ProjectView">\n     <navigator proportions="" version="1">\n       <foldersAlwaysOnTop value="true" />\n@@ -125,6 +211,16 @@\n               <item name="face_recognition_pfe" type="b2602c69:ProjectViewProjectNode" />\n               <item name="face_recognition_pfe" type="462c0819:PsiDirectoryNode" />\n             </path>\n+            <path>\n+              <item name="face_recognition_pfe" type="b2602c69:ProjectViewProjectNode" />\n+              <item name="face_recognition_pfe" type="462c0819:PsiDirectoryNode" />\n+              <item name="align" type="462c0819:PsiDirectoryNode" />\n+            </path>\n+            <path>\n+              <item name="face_recognition_pfe" type="b2602c69:ProjectViewProjectNode" />\n+              <item name="face_recognition_pfe" type="462c0819:PsiDirectoryNode" />\n+              <item name="models" type="462c0819:PsiDirectoryNode" />\n+            </path>\n           </expand>\n           <select />\n         </subPane>\n@@ -132,6 +228,7 @@\n     </panes>\n   </component>\n   <component name="PropertiesComponent">\n+    <property name="SHARE_PROJECT_CONFIGURATION_FILES" value="true" />\n     <property name="last_opened_file_path" value="$PROJECT_DIR$" />\n     <property name="settings.editor.selected.configurable" value="com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable" />\n   </component>\n@@ -147,7 +244,7 @@\n       </list>\n     </option>\n   </component>\n-  <component name="RunManager" selected="Python.real_time_face_recognition_ip_webcam">\n+  <component name="RunManager" selected="Python.train_tripletloss">\n     <configuration name="align_dataset_mtcnn" type="PythonConfigurationType" factoryName="Python" temporary="true">\n       <module name="face_recognition_pfe" />\n       <option name="INTERPRETER_OPTIONS" value="" />\n@@ -169,7 +266,7 @@\n       <option name="INPUT_FILE" value="" />\n       <method v="2" />\n     </configuration>\n-    <configuration name="classifier" type="PythonConfigurationType" factoryName="Python" temporary="true">\n+    <configuration name="cluster" type="PythonConfigurationType" factoryName="Python" temporary="true">\n       <module name="face_recognition_pfe" />\n       <option name="INTERPRETER_OPTIONS" value="" />\n       <option name="PARENT_ENVS" value="true" />\n@@ -181,7 +278,7 @@\n       <option name="IS_MODULE_SDK" value="true" />\n       <option name="ADD_CONTENT_ROOTS" value="true" />\n       <option name="ADD_SOURCE_ROOTS" value="true" />\n-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/classifier.py" />\n+      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/cluster.py" />\n       <option name="PARAMETERS" value="" />\n       <option name="SHOW_COMMAND_LINE" value="false" />\n       <option name="EMULATE_TERMINAL" value="false" />\n@@ -190,7 +287,7 @@\n       <option name="INPUT_FILE" value="" />\n       <method v="2" />\n     </configuration>\n-    <configuration name="face" type="PythonConfigurationType" factoryName="Python" temporary="true">\n+    <configuration name="clustering" type="PythonConfigurationType" factoryName="Python" temporary="true">\n       <module name="face_recognition_pfe" />\n       <option name="INTERPRETER_OPTIONS" value="" />\n       <option name="PARENT_ENVS" value="true" />\n@@ -202,7 +299,7 @@\n       <option name="IS_MODULE_SDK" value="true" />\n       <option name="ADD_CONTENT_ROOTS" value="true" />\n       <option name="ADD_SOURCE_ROOTS" value="true" />\n-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/face.py" />\n+      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/clustering.py" />\n       <option name="PARAMETERS" value="" />\n       <option name="SHOW_COMMAND_LINE" value="false" />\n       <option name="EMULATE_TERMINAL" value="false" />\n@@ -211,7 +308,7 @@\n       <option name="INPUT_FILE" value="" />\n       <method v="2" />\n     </configuration>\n-    <configuration name="real_time_face_recognition_ip_webcam" type="PythonConfigurationType" factoryName="Python" temporary="true">\n+    <configuration name="real_time_face_recognition_laptop_cam" type="PythonConfigurationType" factoryName="Python" temporary="true">\n       <module name="face_recognition_pfe" />\n       <option name="INTERPRETER_OPTIONS" value="" />\n       <option name="PARENT_ENVS" value="true" />\n@@ -223,7 +320,7 @@\n       <option name="IS_MODULE_SDK" value="true" />\n       <option name="ADD_CONTENT_ROOTS" value="true" />\n       <option name="ADD_SOURCE_ROOTS" value="true" />\n-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/real_time_face_recognition_ip_webcam.py" />\n+      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/real_time_face_recognition_laptop_cam.py" />\n       <option name="PARAMETERS" value="" />\n       <option name="SHOW_COMMAND_LINE" value="false" />\n       <option name="EMULATE_TERMINAL" value="false" />\n@@ -232,7 +329,7 @@\n       <option name="INPUT_FILE" value="" />\n       <method v="2" />\n     </configuration>\n-    <configuration name="real_time_face_recognition_laptop_cam" type="PythonConfigurationType" factoryName="Python" temporary="true">\n+    <configuration name="train_tripletloss" type="PythonConfigurationType" factoryName="Python" temporary="true">\n       <module name="face_recognition_pfe" />\n       <option name="INTERPRETER_OPTIONS" value="" />\n       <option name="PARENT_ENVS" value="true" />\n@@ -244,7 +341,7 @@\n       <option name="IS_MODULE_SDK" value="true" />\n       <option name="ADD_CONTENT_ROOTS" value="true" />\n       <option name="ADD_SOURCE_ROOTS" value="true" />\n-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/real_time_face_recognition_laptop_cam.py" />\n+      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/train_tripletloss.py" />\n       <option name="PARAMETERS" value="" />\n       <option name="SHOW_COMMAND_LINE" value="false" />\n       <option name="EMULATE_TERMINAL" value="false" />\n@@ -255,10 +352,10 @@\n     </configuration>\n     <recent_temporary>\n       <list>\n-        <item itemvalue="Python.real_time_face_recognition_ip_webcam" />\n+        <item itemvalue="Python.train_tripletloss" />\n+        <item itemvalue="Python.cluster" />\n         <item itemvalue="Python.real_time_face_recognition_laptop_cam" />\n-        <item itemvalue="Python.classifier" />\n-        <item itemvalue="Python.face" />\n+        <item itemvalue="Python.clustering" />\n         <item itemvalue="Python.align_dataset_mtcnn" />\n       </list>\n     </recent_temporary>\n@@ -277,11 +374,10 @@\n     <servers />\n   </component>\n   <component name="ToolWindowManager">\n-    <frame x="-7" y="-7" width="1550" height="838" extended-state="7" />\n-    <editor active="true" />\n+    <frame x="-7" y="-7" width="1550" height="838" extended-state="6" />\n     <layout>\n       <window_info id="Favorites" order="0" side_tool="true" />\n-      <window_info content_ui="combo" id="Project" order="1" visible="true" weight="0.24966975" />\n+      <window_info active="true" content_ui="combo" id="Project" order="1" visible="true" weight="0.24966975" />\n       <window_info id="Structure" order="2" side_tool="true" weight="0.25" />\n       <window_info anchor="bottom" id="Terminal" order="0" weight="0.32956153" />\n       <window_info anchor="bottom" id="Event Log" order="1" side_tool="true" />\n@@ -289,7 +385,7 @@\n       <window_info anchor="bottom" id="Message" order="3" />\n       <window_info anchor="bottom" id="Find" order="4" />\n       <window_info anchor="bottom" id="Version Control" order="5" />\n-      <window_info active="true" anchor="bottom" id="Run" order="6" visible="true" weight="0.32956153" />\n+      <window_info anchor="bottom" id="Run" order="6" visible="true" weight="0.32956153" />\n       <window_info anchor="bottom" id="Debug" order="7" weight="0.39886847" />\n       <window_info anchor="bottom" id="Cvs" order="8" weight="0.25" />\n       <window_info anchor="bottom" id="Inspection" order="9" weight="0.4" />\n@@ -298,101 +394,266 @@\n       <window_info anchor="right" id="Ant Build" order="1" weight="0.25" />\n       <window_info anchor="right" content_ui="combo" id="Hierarchy" order="2" weight="0.25" />\n     </layout>\n+    <layout-to-restore>\n+      <window_info id="Favorites" order="0" side_tool="true" />\n+      <window_info content_ui="combo" id="Project" order="1" visible="true" weight="0.24966975" />\n+      <window_info id="Structure" order="2" side_tool="true" weight="0.25" />\n+      <window_info anchor="bottom" id="Terminal" order="0" weight="0.32956153" />\n+      <window_info anchor="bottom" id="Event Log" order="1" side_tool="true" />\n+      <window_info anchor="bottom" id="Python Console" order="2" />\n+      <window_info anchor="bottom" id="Message" order="3" />\n+      <window_info anchor="bottom" id="Find" order="4" />\n+      <window_info anchor="bottom" id="Version Control" order="5" />\n+      <window_info anchor="bottom" id="Run" order="6" weight="0.32956153" />\n+      <window_info anchor="bottom" id="Debug" order="7" weight="0.39886847" />\n+      <window_info anchor="bottom" id="Cvs" order="8" weight="0.25" />\n+      <window_info anchor="bottom" id="Inspection" order="9" weight="0.4" />\n+      <window_info anchor="bottom" id="TODO" order="10" />\n+      <window_info anchor="right" id="Commander" internal_type="SLIDING" order="0" type="SLIDING" weight="0.4" />\n+      <window_info anchor="right" id="Ant Build" order="1" weight="0.25" />\n+      <window_info anchor="right" content_ui="combo" id="Hierarchy" order="2" weight="0.25" />\n+    </layout-to-restore>\n+  </component>\n+  <component name="XDebuggerManager">\n+    <breakpoint-manager>\n+      <breakpoints>\n+        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">\n+          <url>file://C:/ProgramData/Anaconda3/envs/faceNet/Lib/site-packages/tensorflow/python/client/session.py</url>\n+          <line>16</line>\n+          <option name="timeStamp" value="1" />\n+        </line-breakpoint>\n+      </breakpoints>\n+    </breakpoint-manager>\n   </component>\n   <component name="editorHistoryManager">\n-    <entry file="file://$USER_HOME$/Anaconda3/envs/faceNet/Lib/importlib/__init__.py">\n+    <entry file="file://$USER_HOME$/Anaconda3/envs/faceNet/Lib/importlib/__init__.py" />\n+    <entry file="file://$USER_HOME$/Anaconda3/envs/faceNet/Lib/site-packages/tensorflow/python/framework/load_library.py" />\n+    <entry file="file://$USER_HOME$/Anaconda3/envs/faceNet/Lib/encodings/cp1252.py" />\n+    <entry file="file://$PROJECT_DIR$/train_softmax.py" />\n+    <entry file="file://$USER_HOME$/Anaconda3/envs/faceNet/Lib/urllib/request.py" />\n+    <entry file="file://$USER_HOME$/Anaconda3/envs/faceNet/Lib/site-packages/PIL/Image.py" />\n+    <entry file="file://$USER_HOME$/Anaconda3/envs/IAVE/Lib/site-packages/tensorflow/python/keras/backend/__init__.py" />\n+    <entry file="file://$PROJECT_DIR$/test.jpg" />\n+    <entry file="file://C:/ProgramData/Anaconda3/envs/faceNet/Lib/site-packages/numpy/lib/format.py">\n+      <provider selected="true" editor-type-id="text-editor">\n+        <state relative-caret-position="18">\n+          <caret line="651" selection-start-line="651" selection-end-line="651" />\n+        </state>\n+      </provider>\n+    </entry>\n+    <entry file="file://$PROJECT_DIR$/requirements.txt" />\n+    <entry file="file://$PROJECT_DIR$/real_time_face_recognition_ip_webcam.py">\n+      <provider selected="true" editor-type-id="text-editor">\n+        <state relative-caret-position="176">\n+          <caret line="54" column="39" selection-start-line="54" selection-start-column="39" selection-end-line="54" selection-end-column="39" />\n+          <folding>\n+            <element signature="e#1245#1260#0" expanded="true" />\n+          </folding>\n+        </state>\n+      </provider>\n+    </entry>\n+    <entry file="file://C:/ProgramData/Anaconda3/envs/faceNet/Lib/site-packages/tensorflow/python/framework/ops.py">\n       <provider selected="true" editor-type-id="text-editor">\n         <state relative-caret-position="141">\n-          <caret line="125" selection-start-line="125" selection-end-line="125" />\n+          <caret line="1569" selection-start-line="1569" selection-end-line="1569" />\n         </state>\n       </provider>\n     </entry>\n-    <entry file="file://$USER_HOME$/Anaconda3/envs/faceNet/Lib/site-packages/tensorflow/python/framework/load_library.py">\n+    <entry file="file://$PROJECT_DIR$/compare.py">\n       <provider selected="true" editor-type-id="text-editor">\n-        <state relative-caret-position="256">\n-          <caret line="55" column="21" selection-start-line="55" selection-start-column="21" selection-end-line="55" selection-end-column="35" />\n+        <state relative-caret-position="13">\n+          <caret line="41" column="33" selection-start-line="41" selection-start-column="33" selection-end-line="41" selection-end-column="33" />\n         </state>\n       </provider>\n     </entry>\n-    <entry file="file://$PROJECT_DIR$/train_tripletloss.py">\n+    <entry file="file://$PROJECT_DIR$/detect_face.py">\n       <provider selected="true" editor-type-id="text-editor">\n-        <state relative-caret-position="-108">\n-          <caret line="6" column="2" selection-start-line="6" selection-start-column="2" selection-end-line="6" selection-end-column="2" />\n+        <state relative-caret-position="-3942" />\n+      </provider>\n+    </entry>\n+    <entry file="file://$PROJECT_DIR$/testCluster.py" />\n+    <entry file="file://C:/ProgramData/Anaconda3/envs/faceNet/Lib/site-packages/numpy/core/numeric.py">\n+      <provider selected="true" editor-type-id="text-editor">\n+        <state relative-caret-position="285">\n+          <caret line="466" lean-forward="true" selection-start-line="466" selection-end-line="466" />\n+        </state>\n+      </provider>\n+    </entry>\n+    <entry file="file://C:/ProgramData/Anaconda3/envs/faceNet/Lib/site-packages/tensorflow/python/client/session.py">\n+      <provider selected="true" editor-type-id="text-editor">\n+        <state relative-caret-position="141">\n+          <caret line="1103" selection-start-line="1103" selection-end-line="1103" />\n           <folding>\n-            <element signature="e#1289#1327#0" expanded="true" />\n+            <element signature="e#731#769#0" expanded="true" />\n           </folding>\n         </state>\n       </provider>\n     </entry>\n-    <entry file="file://$USER_HOME$/Anaconda3/envs/faceNet/Lib/encodings/cp1252.py">\n+    <entry file="file://$PROJECT_DIR$/classifier.py">\n+      <provider selected="true" editor-type-id="text-editor">\n+        <state relative-caret-position="216">\n+          <caret line="12" column="2" selection-start-line="12" selection-start-column="2" selection-end-line="12" selection-end-column="2" />\n+          <folding>\n+            <element signature="e#1209#1247#0" expanded="true" />\n+          </folding>\n+        </state>\n+      </provider>\n+    </entry>\n+    <entry file="file://$USER_HOME$/.conda/envs/faceRecognition/Lib/site-packages/numpy/core/fromnumeric.py">\n       <provider selected="true" editor-type-id="text-editor">\n         <state relative-caret-position="141">\n-          <caret line="18" column="16" selection-start-line="18" selection-start-column="16" selection-end-line="18" selection-end-column="16" />\n+          <caret line="50" selection-start-line="50" selection-end-line="50" />\n         </state>\n       </provider>\n     </entry>\n-    <entry file="file://$PROJECT_DIR$/train_softmax.py">\n+    <entry file="file://$USER_HOME$/.conda/envs/faceRecognition/Lib/site-packages/numpy/core/numeric.py">\n       <provider selected="true" editor-type-id="text-editor">\n-        <state relative-caret-position="150">\n-          <caret line="71" column="28" selection-start-line="71" selection-start-column="28" selection-end-line="71" selection-end-column="28" />\n+        <state relative-caret-position="148">\n+          <caret line="500" selection-start-line="500" selection-end-line="500" />\n         </state>\n       </provider>\n     </entry>\n-    <entry file="file://$PROJECT_DIR$/classifier.py">\n+    <entry file="file://$USER_HOME$/.conda/envs/faceRecognition/Lib/site-packages/tensorflow/python/client/session.py">\n+      <provider selected="true" editor-type-id="text-editor">\n+        <state relative-caret-position="141">\n+          <caret line="1103" selection-start-line="1103" selection-end-line="1103" />\n+        </state>\n+      </provider>\n+    </entry>\n+    <entry file="file://$USER_HOME$/.conda/envs/faceRecognition/Lib/site-packages/tensorflow/python/framework/ops.py">\n+      <provider selected="true" editor-type-id="text-editor">\n+        <state relative-caret-position="-723">\n+          <caret line="3539" selection-start-line="3539" selection-end-line="3539" />\n+        </state>\n+      </provider>\n+    </entry>\n+    <entry file="file://$USER_HOME$/.conda/envs/faceRecognition/Lib/site-packages/tensorflow/python/framework/importer.py">\n       <provider selected="true" editor-type-id="text-editor">\n         <state relative-caret-position="148">\n-          <caret line="40" column="33" lean-forward="true" selection-start-line="40" selection-start-column="33" selection-end-line="40" selection-end-column="33" />\n+          <caret line="512" selection-start-line="512" selection-end-line="512" />\n+        </state>\n+      </provider>\n+    </entry>\n+    <entry file="file://$USER_HOME$/.conda/envs/faceRecognition/Lib/site-packages/tensorflow/python/util/deprecation.py">\n+      <provider selected="true" editor-type-id="text-editor">\n+        <state relative-caret-position="148">\n+          <caret line="431" selection-start-line="431" selection-end-line="431" />\n+        </state>\n+      </provider>\n+    </entry>\n+    <entry file="file://$PROJECT_DIR$/face.py">\n+      <provider selected="true" editor-type-id="text-editor">\n+        <state relative-caret-position="222">\n+          <caret line="100" selection-start-line="100" selection-end-line="100" />\n+        </state>\n+      </provider>\n+    </entry>\n+    <entry file="file://$PROJECT_DIR$/send_package.py">\n+      <provider selected="true" editor-type-id="text-editor">\n+        <state relative-caret-position="186">\n+          <caret line="26" column="55" selection-start-line="26" selection-start-column="41" selection-end-line="26" selection-end-column="55" />\n           <folding>\n-            <element signature="e#1209#1247#0" expanded="true" />\n+            <element signature="e#0#11#0" expanded="true" />\n           </folding>\n         </state>\n       </provider>\n     </entry>\n-    <entry file="file://$PROJECT_DIR$/facenet.py">\n+    <entry file="file://$USER_HOME$/.PyCharmCE2019.1/system/python_stubs/-1670176069/numpy/core/_multiarray_umath.py">\n+      <provider selected="true" editor-type-id="text-editor">\n+        <state relative-caret-position="148">\n+          <caret line="3751" column="4" selection-start-line="3751" selection-start-column="4" selection-end-line="3751" selection-end-column="4" />\n+        </state>\n+      </provider>\n+    </entry>\n+    <entry file="file://$PROJECT_DIR$/clustering.py">\n       <provider selected="true" editor-type-id="text-editor">\n-        <state relative-caret-position="2562">\n-          <caret line="493" column="37" selection-start-line="493" selection-start-column="37" selection-end-line="493" selection-end-column="37" />\n+        <state relative-caret-position="132">\n+          <caret line="239" selection-start-line="239" selection-end-line="239" />\n+          <folding>\n+            <element signature="e#21#44#0" expanded="true" />\n+          </folding>\n         </state>\n       </provider>\n     </entry>\n-    <entry file="file://$USER_HOME$/Anaconda3/envs/faceNet/Lib/urllib/request.py">\n+    <entry file="file://$USER_HOME$/.conda/envs/faceRecognition/Lib/site-packages/numpy/lib/utils.py">\n       <provider selected="true" editor-type-id="text-editor">\n-        <state relative-caret-position="310">\n-          <caret line="457" selection-start-line="457" selection-end-line="457" />\n+        <state relative-caret-position="1566">\n+          <caret line="100" selection-start-line="100" selection-end-line="100" />\n         </state>\n       </provider>\n     </entry>\n-    <entry file="file://$PROJECT_DIR$/align/align_dataset_mtcnn.py">\n+    <entry file="file://$USER_HOME$/.conda/envs/faceRecognition/Lib/site-packages/PIL/Image.py">\n+      <provider selected="true" editor-type-id="text-editor">\n+        <state relative-caret-position="828">\n+          <caret line="46" lean-forward="true" selection-start-line="46" selection-end-line="46" />\n+          <folding>\n+            <element signature="e#873#933#0" expanded="true" />\n+          </folding>\n+        </state>\n+      </provider>\n+    </entry>\n+    <entry file="file://$USER_HOME$/.conda/envs/faceRecognition/Lib/site-packages/scipy/misc/pilutil.py">\n+      <provider selected="true" editor-type-id="text-editor">\n+        <state relative-caret-position="148">\n+          <caret line="163" selection-start-line="163" selection-end-line="163" />\n+        </state>\n+      </provider>\n+    </entry>\n+    <entry file="file://$USER_HOME$/.conda/envs/faceRecognition/Lib/random.py">\n       <provider selected="true" editor-type-id="text-editor">\n-        <state relative-caret-position="522">\n-          <caret line="81" column="22" selection-start-line="81" selection-start-column="22" selection-end-line="81" selection-end-column="22" />\n+        <state relative-caret-position="195">\n+          <caret line="280" selection-start-line="280" selection-end-line="280" />\n         </state>\n       </provider>\n     </entry>\n     <entry file="file://$PROJECT_DIR$/real_time_face_recognition_laptop_cam.py">\n       <provider selected="true" editor-type-id="text-editor">\n-        <state relative-caret-position="-396">\n-          <caret line="31" column="44" lean-forward="true" selection-start-line="31" selection-start-column="44" selection-end-line="31" selection-end-column="44" />\n+        <state relative-caret-position="738">\n+          <caret line="41" column="21" selection-start-line="41" selection-start-column="21" selection-end-line="41" selection-end-column="21" />\n+        </state>\n+      </provider>\n+    </entry>\n+    <entry file="file://$PROJECT_DIR$/align/detect_face.py">\n+      <provider selected="true" editor-type-id="text-editor">\n+        <state relative-caret-position="5724">\n+          <caret line="327" column="44" selection-start-line="327" selection-start-column="44" selection-end-line="327" selection-end-column="44" />\n+        </state>\n+      </provider>\n+    </entry>\n+    <entry file="file://$PROJECT_DIR$/align/align_dataset_mtcnn.py">\n+      <provider selected="true" editor-type-id="text-editor">\n+        <state relative-caret-position="486">\n+          <caret line="40" column="46" selection-start-line="40" selection-start-column="46" selection-end-line="40" selection-end-column="46" />\n           <folding>\n-            <element signature="e#1245#1260#0" expanded="true" />\n+            <element signature="e#1196#1234#0" expanded="true" />\n           </folding>\n         </state>\n       </provider>\n     </entry>\n-    <entry file="file://$PROJECT_DIR$/real_time_face_recognition_ip_webcam.py">\n+    <entry file="file://$PROJECT_DIR$/facenet.py">\n       <provider selected="true" editor-type-id="text-editor">\n-        <state relative-caret-position="-252">\n-          <caret line="38" column="51" lean-forward="true" selection-start-line="38" selection-start-column="51" selection-end-line="38" selection-end-column="51" />\n+        <state relative-caret-position="3924">\n+          <caret line="233" selection-start-line="233" selection-end-line="233" />\n+        </state>\n+      </provider>\n+    </entry>\n+    <entry file="file://$PROJECT_DIR$/cluster.py">\n+      <provider selected="true" editor-type-id="text-editor">\n+        <state relative-caret-position="440">\n+          <caret line="93" column="31" selection-start-line="93" selection-start-column="31" selection-end-line="93" selection-end-column="31" />\n           <folding>\n-            <element signature="e#1245#1260#0" expanded="true" />\n+            <element signature="e#1217#1255#0" expanded="true" />\n           </folding>\n         </state>\n       </provider>\n     </entry>\n-    <entry file="file://$PROJECT_DIR$/face.py">\n+    <entry file="file://$PROJECT_DIR$/train_tripletloss.py">\n       <provider selected="true" editor-type-id="text-editor">\n-        <state relative-caret-position="132">\n-          <caret line="123" column="22" lean-forward="true" selection-start-line="123" selection-start-column="22" selection-end-line="123" selection-end-column="22" />\n+        <state relative-caret-position="173">\n+          <caret line="445" column="42" lean-forward="true" selection-start-line="445" selection-start-column="42" selection-end-line="445" selection-end-column="42" />\n+          <folding>\n+            <element signature="e#1289#1327#0" expanded="true" />\n+          </folding>\n         </state>\n       </provider>\n     </entry>\ndiff --git a/__pycache__/detect_face.cpython-35.pyc b/__pycache__/detect_face.cpython-35.pyc\ndeleted file mode 100644\nindex 12b0c5e..0000000\nBinary files a/__pycache__/detect_face.cpython-35.pyc and /dev/null differ\ndiff --git a/__pycache__/face.cpython-35.pyc b/__pycache__/face.cpython-35.pyc\nindex dd54086..52ad26f 100644\nBinary files a/__pycache__/face.cpython-35.pyc and b/__pycache__/face.cpython-35.pyc differ\ndiff --git a/__pycache__/facenet.cpython-35.pyc b/__pycache__/facenet.cpython-35.pyc\nindex 6650bac..80180df 100644\nBinary files a/__pycache__/facenet.cpython-35.pyc and b/__pycache__/facenet.cpython-35.pyc differ\ndiff --git a/align/__pycache__/detect_face.cpython-35.pyc b/align/__pycache__/detect_face.cpython-35.pyc\nindex ed4ba8f..5c87277 100644\nBinary files a/align/__pycache__/detect_face.cpython-35.pyc and b/align/__pycache__/detect_face.cpython-35.pyc differ\ndiff --git a/align/align_dataset_mtcnn.py b/align/align_dataset_mtcnn.py\nindex 751fc56..89342f6 100644\n--- a/align/align_dataset_mtcnn.py\n+++ b/align/align_dataset_mtcnn.py\n@@ -122,6 +122,8 @@ def main(args):\n                                 bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\n                                 cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n                                 scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\'bilinear\')\n+                                #####i added this one to scale it in gray but maybe i will remove it later\n+                                scaledGray = np.dot(scaled[...,:3], [0.2989, 0.5870, 0.1140])\n                                 nrof_successfully_aligned += 1\n                                 filename_base, file_extension = os.path.splitext(output_filename)\n                                 if args.detect_multiple_faces:\n@@ -144,7 +146,7 @@ def parse_arguments(argv):\n     \'\'\'parser.add_argument(\'input_dir\', type=str, help=\'Directory with unaligned images.\')\n     parser.add_argument(\'output_dir\', type=str, help=\'Directory with aligned face thumbnails.\')\'\'\'\n     parser.add_argument(\'--image_size\', type=int,\n-        help=\'Image size (height, width) in pixels.\', default=182)\n+        help=\'Image size (height, width) in pixels.\', default=160)\n     parser.add_argument(\'--margin\', type=int,\n         help=\'Margin for the crop around the bounding box (height, width) in pixels.\', default=44)\n     parser.add_argument(\'--random_order\', \n@@ -152,7 +154,7 @@ def parse_arguments(argv):\n     parser.add_argument(\'--gpu_memory_fraction\', type=float,\n         help=\'Upper bound on the amount of GPU memory that will be used by the process.\', default=1.0)\n     parser.add_argument(\'--detect_multiple_faces\', type=bool,\n-                        help=\'Detect and align multiple faces per image.\', default=False)\n+                        help=\'Detect and align multiple faces per image.\', default=True)\n     return parser.parse_args(argv)\n \n if __name__ == \'__main__\':\ndiff --git a/compare.py b/compare.py\nindex bc53cc4..f34526d 100644\n--- a/compare.py\n+++ b/compare.py\n@@ -38,13 +38,12 @@ import align.detect_face\n \n def main(args):\n \n-    images = load_and_align_data(args.image_files, args.image_size, args.margin, args.gpu_memory_fraction)\n+    images = load_and_align_data("*.png temp_input/WIN_20190603_03_41_21_Pro.jpg", args.image_size, args.margin, args.gpu_memory_fraction)\n     with tf.Graph().as_default():\n-\n         with tf.Session() as sess:\n       \n             # Load the model\n-            facenet.load_model(args.model)\n+            facenet.load_model(\'./models/\')\n     \n             # Get input and output tensors\n             images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")\n@@ -55,11 +54,11 @@ def main(args):\n             feed_dict = { images_placeholder: images, phase_train_placeholder:False }\n             emb = sess.run(embeddings, feed_dict=feed_dict)\n             \n-            nrof_images = len(args.image_files)\n+            nrof_images = len(\'./temp_input/WIN_20190603_03_41_21_Pro.jpg\')\n \n             print(\'Images:\')\n             for i in range(nrof_images):\n-                print(\'%1d: %s\' % (i, args.image_files[i]))\n+                print(\'%1d: %s\' % (i, \'./temp_input/WIN_20190603_03_41_21_Pro.jpg\'[i]))\n             print(\'\')\n             \n             # Print distance matrix\n@@ -115,9 +114,9 @@ def load_and_align_data(image_paths, image_size, margin, gpu_memory_fraction):\n def parse_arguments(argv):\n     parser = argparse.ArgumentParser()\n     \n-    parser.add_argument(\'model\', type=str, \n+    \'\'\'parser.add_argument(\'model\', type=str, \n         help=\'Could be either a directory containing the meta_file and ckpt_file or a model protobuf (.pb) file\')\n-    parser.add_argument(\'image_files\', type=str, nargs=\'+\', help=\'Images to compare\')\n+    parser.add_argument(\'image_files\', type=str, nargs=\'+\', help=\'Images to compare\')\'\'\'\n     parser.add_argument(\'--image_size\', type=int,\n         help=\'Image size (height, width) in pixels.\', default=160)\n     parser.add_argument(\'--margin\', type=int,\ndiff --git a/face.py b/face.py\nindex 7bf30d6..188a1ef 100644\n--- a/face.py\n+++ b/face.py\n@@ -46,6 +46,7 @@ classifier_model = os.path.dirname(__file__) + "/myclassifier/my_classifier.pkl"\n debug = False\n \n \n+\n class Face:\n     def __init__(self):\n         self.name = None\n@@ -79,8 +80,6 @@ class Recognition:\n                 cv2.imshow("Face: " + str(i), face.image)\n             face.embedding = self.encoder.generate_embedding(face)\n             face.name =self.identifier.identify(face)\n-            print(\'\\n\')\n-            print(face.name)\n             face.color = (0, 0, 51) if "Intrus" == face.name  else (51, 0, 0)  ###########line that i added for changing color depending on wether the face is recognized or not\n \n         return faces\n@@ -94,9 +93,10 @@ class Identifier:\n     def identify(self, face):\n         if face.embedding is not None:\n             predictions = self.model.predict_proba([face.embedding])\n-            print(predictions)\n+            #####this is just for testing predictions\n+            #print(predictions)\n             best_class_indices = np.argmax(predictions, axis=1)\n-            return self.class_names[best_class_indices[0]] if predictions[0][best_class_indices[0]]>0.6 else "Intrus" ############modified this code\n+            return self.class_names[best_class_indices[0]] if predictions[0][best_class_indices[0]]>0.7 else "Intrus" ############modified this code\n \n \n class Encoder:\n@@ -124,7 +124,7 @@ class Detection:\n     threshold = [0.6, 0.7, 0.7]  # three steps\'s threshold\n     factor = 0.709  # scale factor\n \n-    def __init__(self, face_crop_size=160, face_crop_margin=32):\n+    def __init__(self, face_crop_size=160, face_crop_margin=33):\n         self.pnet, self.rnet, self.onet = self._setup_mtcnn()\n         self.face_crop_size = face_crop_size\n         self.face_crop_margin = face_crop_margin\n@@ -143,8 +143,10 @@ class Detection:\n         bounding_boxes, _ = align.detect_face.detect_face(image, self.minsize,\n                                                           self.pnet, self.rnet, self.onet,\n                                                           self.threshold, self.factor)\n+\n         for bb in bounding_boxes:\n             face = Face()\n+\n             face.container_image = image\n             face.bounding_box = np.zeros(4, dtype=np.int32)\n \ndiff --git a/facenet.py b/facenet.py\nindex 0121449..61a4c80 100644\n--- a/facenet.py\n+++ b/facenet.py\n@@ -515,5 +515,5 @@ def put_images_on_grid(images, shape=(16,8)):\n \n def write_arguments_to_file(args, filename):\n     with open(filename, \'w\') as f:\n-        for key, value in vars(args).iteritems():\n+        for key, value in vars(args).items():\n             f.write(\'%s: %s\\n\' % (key, str(value)))\ndiff --git a/myclassifier/my_classifier.pkl b/myclassifier/my_classifier.pkl\nindex 561e773..1e82957 100644\nBinary files a/myclassifier/my_classifier.pkl and b/myclassifier/my_classifier.pkl differ\ndiff --git a/output/Mahfoudh/WIN_20190527_16_24_02_Pro.png b/output/Mahfoudh/WIN_20190527_16_24_02_Pro.png\ndeleted file mode 100644\nindex 723173f..0000000\nBinary files a/output/Mahfoudh/WIN_20190527_16_24_02_Pro.png and /dev/null differ\ndiff --git a/output/Mahfoudh/WIN_20190530_16_46_19_Pro.png b/output/Mahfoudh/WIN_20190530_16_46_19_Pro.png\ndeleted file mode 100644\nindex dcbf7e2..0000000\nBinary files a/output/Mahfoudh/WIN_20190530_16_46_19_Pro.png and /dev/null differ\ndiff --git a/output/Mahfoudh/WIN_20190530_16_46_21_Pro.png b/output/Mahfoudh/WIN_20190530_16_46_21_Pro.png\ndeleted file mode 100644\nindex aafc7f1..0000000\nBinary files a/output/Mahfoudh/WIN_20190530_16_46_21_Pro.png and /dev/null differ\ndiff --git a/output/Mahfoudh/WIN_20190530_16_46_22_Pro.png b/output/Mahfoudh/WIN_20190530_16_46_22_Pro.png\ndeleted file mode 100644\nindex ed49170..0000000\nBinary files a/output/Mahfoudh/WIN_20190530_16_46_22_Pro.png and /dev/null differ\ndiff --git a/output/Mahfoudh/WIN_20190530_16_46_25_Pro.png b/output/Mahfoudh/WIN_20190530_16_46_25_Pro.png\ndeleted file mode 100644\nindex 31fc7c2..0000000\nBinary files a/output/Mahfoudh/WIN_20190530_16_46_25_Pro.png and /dev/null differ\ndiff --git a/output/Mahfoudh/WIN_20190530_16_46_30_Pro.png b/output/Mahfoudh/WIN_20190530_16_46_30_Pro.png\ndeleted file mode 100644\nindex 5f10033..0000000\nBinary files a/output/Mahfoudh/WIN_20190530_16_46_30_Pro.png and /dev/null differ\ndiff --git a/output/Mahfoudh/WIN_20190531_15_42_20_Pro.png b/output/Mahfoudh/WIN_20190531_15_42_20_Pro.png\ndeleted file mode 100644\nindex e2a2076..0000000\nBinary files a/output/Mahfoudh/WIN_20190531_15_42_20_Pro.png and /dev/null differ\ndiff --git a/output/Mahfoudh/WIN_20190531_15_42_22_Pro.png b/output/Mahfoudh/WIN_20190531_15_42_22_Pro.png\ndeleted file mode 100644\nindex 71dbb63..0000000\nBinary files a/output/Mahfoudh/WIN_20190531_15_42_22_Pro.png and /dev/null differ\ndiff --git a/output/Mahfoudh/WIN_20190531_15_42_24_Pro.png b/output/Mahfoudh/WIN_20190531_15_42_24_Pro.png\ndeleted file mode 100644\nindex c0babfc..0000000\nBinary files a/output/Mahfoudh/WIN_20190531_15_42_24_Pro.png and /dev/null differ\ndiff --git a/output/Mahfoudh/WIN_20190531_15_42_25_Pro.png b/output/Mahfoudh/WIN_20190531_15_42_25_Pro.png\ndeleted file mode 100644\nindex 58c983c..0000000\nBinary files a/output/Mahfoudh/WIN_20190531_15_42_25_Pro.png and /dev/null differ\ndiff --git a/output/Mahfoudh/WIN_20190531_15_42_27_Pro.png b/output/Mahfoudh/WIN_20190531_15_42_27_Pro.png\ndeleted file mode 100644\nindex e353adf..0000000\nBinary files a/output/Mahfoudh/WIN_20190531_15_42_27_Pro.png and /dev/null differ\ndiff --git a/output/Mahfoudh/WIN_20190531_15_42_29_Pro.png b/output/Mahfoudh/WIN_20190531_15_42_29_Pro.png\ndeleted file mode 100644\nindex 54aee40..0000000\nBinary files a/output/Mahfoudh/WIN_20190531_15_42_29_Pro.png and /dev/null differ\ndiff --git a/output/Mahfoudh/imresizer.com (2).png b/output/Mahfoudh/imresizer.com (2).png\ndeleted file mode 100644\nindex 38713fb..0000000\nBinary files a/output/Mahfoudh/imresizer.com (2).png and /dev/null differ\ndiff --git a/output/Mahfoudh/profiles-pic.png b/output/Mahfoudh/profiles-pic.png\ndeleted file mode 100644\nindex 8ad2e6d..0000000\nBinary files a/output/Mahfoudh/profiles-pic.png and /dev/null differ\ndiff --git a/output/dakota/1223426.png b/output/dakota/1223426.png\ndeleted file mode 100644\nindex 03a7fcb..0000000\nBinary files a/output/dakota/1223426.png and /dev/null differ\ndiff --git a/output/dakota/85.png b/output/dakota/85.png\ndeleted file mode 100644\nindex d294c0f..0000000\nBinary files a/output/dakota/85.png and /dev/null differ\ndiff --git a/output/dakota/AP868390099291_1_EffieGray.png b/output/dakota/AP868390099291_1_EffieGray.png\ndeleted file mode 100644\nindex 0de9306..0000000\nBinary files a/output/dakota/AP868390099291_1_EffieGray.png and /dev/null differ\ndiff --git a/output/dakota/Dakota-Fanning-5.png b/output/dakota/Dakota-Fanning-5.png\ndeleted file mode 100644\nindex 02c3cfb..0000000\nBinary files a/output/dakota/Dakota-Fanning-5.png and /dev/null differ\ndiff --git a/output/dakota/Dakota-Fanning.png b/output/dakota/Dakota-Fanning.png\ndeleted file mode 100644\nindex bb49a66..0000000\nBinary files a/output/dakota/Dakota-Fanning.png and /dev/null differ\ndiff --git a/output/dakota/Dakota_Fanning,_2009.png b/output/dakota/Dakota_Fanning,_2009.png\ndeleted file mode 100644\nindex d63466c..0000000\nBinary files a/output/dakota/Dakota_Fanning,_2009.png and /dev/null differ\ndiff --git a/output/dakota/Dakota_Fanning.png b/output/dakota/Dakota_Fanning.png\ndeleted file mode 100644\nindex 1bc739a..0000000\nBinary files a/output/dakota/Dakota_Fanning.png and /dev/null differ\ndiff --git a/output/dakota/Dakota_Fanning_Very_Good_Girls_Premiere_(cropped).png b/output/dakota/Dakota_Fanning_Very_Good_Girls_Premiere_(cropped).png\ndeleted file mode 100644\nindex dc81f8d..0000000\nBinary files a/output/dakota/Dakota_Fanning_Very_Good_Girls_Premiere_(cropped).png and /dev/null differ\ndiff --git a/output/dakota/dakota-fanning (1).png b/output/dakota/dakota-fanning (1).png\ndeleted file mode 100644\nindex d8a7ea0..0000000\nBinary files a/output/dakota/dakota-fanning (1).png and /dev/null differ\ndiff --git a/output/dakota/dakota-fanning,-yeux-bleus-247878.png b/output/dakota/dakota-fanning,-yeux-bleus-247878.png\ndeleted file mode 100644\nindex 0c94cbf..0000000\nBinary files a/output/dakota/dakota-fanning,-yeux-bleus-247878.png and /dev/null differ\ndiff --git a/output/dakota/dakota-fanning-28183-display.png b/output/dakota/dakota-fanning-28183-display.png\ndeleted file mode 100644\nindex 2a22458..0000000\nBinary files a/output/dakota/dakota-fanning-28183-display.png and /dev/null differ\ndiff --git a/output/dakota/dakota-fanning-6.png b/output/dakota/dakota-fanning-6.png\ndeleted file mode 100644\nindex fe3067a..0000000\nBinary files a/output/dakota/dakota-fanning-6.png and /dev/null differ\ndiff --git a/output/dakota/dakota-fanning-by-daniel-bergeron.png b/output/dakota/dakota-fanning-by-daniel-bergeron.png\ndeleted file mode 100644\nindex aee5a8f..0000000\nBinary files a/output/dakota/dakota-fanning-by-daniel-bergeron.png and /dev/null differ\ndiff --git a/output/dakota/dakota_fanning_getty_h_2016.png b/output/dakota/dakota_fanning_getty_h_2016.png\ndeleted file mode 100644\nindex 77965a6..0000000\nBinary files a/output/dakota/dakota_fanning_getty_h_2016.png and /dev/null differ\ndiff --git a/output/obama/1024px-Barack_Obama_speaks_in_Cairo,_Egypt_06-04-09.png b/output/obama/1024px-Barack_Obama_speaks_in_Cairo,_Egypt_06-04-09.png\ndeleted file mode 100644\nindex be80f8a..0000000\nBinary files a/output/obama/1024px-Barack_Obama_speaks_in_Cairo,_Egypt_06-04-09.png and /dev/null differ\ndiff --git a/output/obama/1028782502.png b/output/obama/1028782502.png\ndeleted file mode 100644\nindex ca4ecd5..0000000\nBinary files a/output/obama/1028782502.png and /dev/null differ\ndiff --git a/output/obama/104656161-gettyimages-688156110.1910x1000.png b/output/obama/104656161-gettyimages-688156110.1910x1000.png\ndeleted file mode 100644\nindex e3bbda5..0000000\nBinary files a/output/obama/104656161-gettyimages-688156110.1910x1000.png and /dev/null differ\ndiff --git a/output/obama/170px-BarackObamaportrait.png b/output/obama/170px-BarackObamaportrait.png\ndeleted file mode 100644\nindex 7366868..0000000\nBinary files a/output/obama/170px-BarackObamaportrait.png and /dev/null differ\ndiff --git a/output/obama/190307-barack-obama-al-0826_3c9fdc71dc9476f764088b0e0290fd95.nbcnews-fp-760-360.png b/output/obama/190307-barack-obama-al-0826_3c9fdc71dc9476f764088b0e0290fd95.nbcnews-fp-760-360.png\ndeleted file mode 100644\nindex d63ec05..0000000\nBinary files a/output/obama/190307-barack-obama-al-0826_3c9fdc71dc9476f764088b0e0290fd95.nbcnews-fp-760-360.png and /dev/null differ\ndiff --git a/output/obama/984661-barack-obama-lors-de-sa-derniere-conference-de-presse-a-la-maison-blanche-a-washington-le-18-janvier (1).png b/output/obama/984661-barack-obama-lors-de-sa-derniere-conference-de-presse-a-la-maison-blanche-a-washington-le-18-janvier (1).png\ndeleted file mode 100644\nindex 495af1b..0000000\nBinary files a/output/obama/984661-barack-obama-lors-de-sa-derniere-conference-de-presse-a-la-maison-blanche-a-washington-le-18-janvier (1).png and /dev/null differ\ndiff --git a/output/obama/984661-barack-obama-lors-de-sa-derniere-conference-de-presse-a-la-maison-blanche-a-washington-le-18-janvier.png b/output/obama/984661-barack-obama-lors-de-sa-derniere-conference-de-presse-a-la-maison-blanche-a-washington-le-18-janvier.png\ndeleted file mode 100644\nindex 495af1b..0000000\nBinary files a/output/obama/984661-barack-obama-lors-de-sa-derniere-conference-de-presse-a-la-maison-blanche-a-washington-le-18-janvier.png and /dev/null differ\ndiff --git a/output/obama/Barack-Obama-en-campagne-derriere-les-democrates-pour-reconquerir-le-Congres.png b/output/obama/Barack-Obama-en-campagne-derriere-les-democrates-pour-reconquerir-le-Congres.png\ndeleted file mode 100644\nindex 400bf89..0000000\nBinary files a/output/obama/Barack-Obama-en-campagne-derriere-les-democrates-pour-reconquerir-le-Congres.png and /dev/null differ\ndiff --git a/output/obama/Barack-Obama.png b/output/obama/Barack-Obama.png\ndeleted file mode 100644\nindex 398da9c..0000000\nBinary files a/output/obama/Barack-Obama.png and /dev/null differ\ndiff --git a/output/obama/_93339875_obamalaughing.png b/output/obama/_93339875_obamalaughing.png\ndeleted file mode 100644\nindex d3acac4..0000000\nBinary files a/output/obama/_93339875_obamalaughing.png and /dev/null differ\ndiff --git "a/output/obama/barack\\303\\2502.png" "b/output/obama/barack\\303\\2502.png"\ndeleted file mode 100644\nindex dd4f956..0000000\nBinary files "a/output/obama/barack\\303\\2502.png" and /dev/null differ\ndiff --git a/output/obama/images (4).png b/output/obama/images (4).png\ndeleted file mode 100644\nindex c764487..0000000\nBinary files a/output/obama/images (4).png and /dev/null differ\ndiff --git a/output/obama/images (5).png b/output/obama/images (5).png\ndeleted file mode 100644\nindex 565dc2c..0000000\nBinary files a/output/obama/images (5).png and /dev/null differ\ndiff --git a/output/obama/obama_sotu_2016_ap_img.png b/output/obama/obama_sotu_2016_ap_img.png\ndeleted file mode 100644\nindex 588525f..0000000\nBinary files a/output/obama/obama_sotu_2016_ap_img.png and /dev/null differ\ndiff --git a/real_time_face_recognition_ip_webcam.py b/real_time_face_recognition_ip_webcam.py\nindex 5ffb45b..79f29b3 100644\n--- a/real_time_face_recognition_ip_webcam.py\n+++ b/real_time_face_recognition_ip_webcam.py\n@@ -55,7 +55,7 @@ def main(args):\n     fps_display_interval = 5  # seconds\n     frame_rate = 0\n     frame_count = 0\n-    url = \'http://192.168.1.3:8080/shot.jpg?rnd=220856\'\n+    url = \'http://192.168.43.1:8080/shot.jpg?rnd=702825\'\n \n     face_recognition = face.Recognition()\n     start_time = time.time()\ndiff --git a/real_time_face_recognition_laptop_cam.py b/real_time_face_recognition_laptop_cam.py\nindex 7eb68d3..c5efbd3 100644\n--- a/real_time_face_recognition_laptop_cam.py\n+++ b/real_time_face_recognition_laptop_cam.py\n@@ -36,16 +36,19 @@ Based on code from https://github.com/shanren7/real_time_face_recognition\n import argparse\n import sys\n import time\n-\n+import numpy as np\n import cv2\n-\n import face\n+from PIL import Image\n+import send_package as sp\n+import pika\n \n ############# propri\xc3\xa9t\xc3\xa9s du bouding box (ma touchihach mohamed)\n def add_overlays(frame, faces, frame_rate):\n     if faces is not None:\n         for face in faces:\n             face_bb = face.bounding_box.astype(int)\n+            print(face_bb)\n             cv2.rectangle(frame,\n                           (face_bb[0], face_bb[1]), (face_bb[2], face_bb[3]),\n                           face.color, 2)\n@@ -59,16 +62,32 @@ def add_overlays(frame, faces, frame_rate):\n                 thickness=2, lineType=2)\n \n \n+\n+######Get the name of each face detected\n+def get_name(faces):\n+    if faces is not None:\n+        for face in faces:\n+             return face.name\n+\n+\n+\n def main(args):\n-    frame_interval = 2  # Number of frames after which to run face detection\n-    fps_display_interval = 5  # seconds\n+    frame_interval = 1  # Number of frames after which to run face detection\n+    fps_display_interval = 1  # seconds\n     frame_rate = 0\n     frame_count = 0\n-\n-\n+    imageNumber= 0\n     video_capture = cv2.VideoCapture(0)\n     face_recognition = face.Recognition()\n     start_time = time.time()\n+    credentials = pika.PlainCredentials(\'mak\',\'26121997\')\n+    HOST =\'localhost\'\n+\n+    ######Creating communication channel between 2 computers\n+    connexion = pika.BlockingConnection(pika.ConnectionParameters(host=HOST,credentials=credentials))\n+    channel=connexion.channel()\n+    channel.queue_declare(queue="messages")\n+\n \n     if args.debug:\n         print("Debug enabled")\n@@ -78,8 +97,27 @@ def main(args):\n         # Capture frame-by-frame\n         ret, frame = video_capture.read()\n \n+        threshold = 110 ####this part is for comparing the blur\n         if (frame_count % frame_interval) == 0:\n             faces = face_recognition.identify(frame)\n+            \'\'\'print(faces)\n+            print(type(faces))\n+            print(len(faces)) this code is just for testing face object\'\'\'\n+            #--------------------------------------------------cuthere--------------------------------------------------\n+            ####this part is for extracting the frame and converting it to rgb\n+            sp.extract_crop_frame(frame,faces,imageNumber)\n+            imageNumber += 1\n+           #------------------------------------------------------------------------------------------------------------\n+\n+\n+            #####get the current face name\n+            if(get_name(faces) == \'Intrus\'):\n+                #####we create a new package object and serialize it\n+                sealed_package = sp.package(frame.tolist(),\'0\').serialize_package()\n+                channel.basic_publish(exchange=\'\',routing_key=\'messages\',body=sealed_package)\n+                print(\'The sealed package is sent\')\n+\n+\n \n \n             # Check our current fps\n@@ -91,15 +129,18 @@ def main(args):\n \n         add_overlays(frame, faces, frame_rate)\n \n+\n         frame_count += 1\n         cv2.imshow(\'Video\', frame)\n \n+\n         if cv2.waitKey(1) & 0xFF == ord(\'q\'):\n             break\n \n     # When everything is done, release the capture\n     video_capture.release()\n     cv2.destroyAllWindows()\n+    connexion.close()\n \n \n def parse_arguments(argv):'